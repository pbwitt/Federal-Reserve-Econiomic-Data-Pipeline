{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "# get the image\n",
    "Image(url=\"DataPipeline.jpeg\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# get the image\n",
    "Image(url=\"Measures-of-Money-Supply.jpeg\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline Overview\n",
    "\n",
    "### Key Feautres:\n",
    "\n",
    "\n",
    "\n",
    "To me, a successful datapipeline should do the following:\n",
    "\n",
    "1) automate data extraction and wrangling. The work is done upfront.  \n",
    "\n",
    "2) produce reusauble code so others can use.  Modules allow others to use them.  \n",
    "\n",
    "3) produce datasets that are optimized for aggegaions. In otherwords, datasets that can be loaded and used for analysis in other applications. appending data, adding \n",
    "\n",
    "For this exercise: I built several custum python modules that do the following:\n",
    "\n",
    "\n",
    "DataPull:\n",
    "\n",
    "pull_data(): \n",
    "\n",
    "Pulls data from 3 API endpoints.  Automatically loops through each endpoint, pulls all avaible data, appends and merges them together.  The result is one raw dataset that can be used for more in-depth analysis, including aggregations and dataqualty checks.  \n",
    "\n",
    "DataWrangle:\n",
    "\n",
    "Cleans, formats and does other custom aggregations to the data pulled from FRED.  Cleans column headings, creates year and month columns.  This module is created seperate from DataPull because there will be a continual need to add new functions in the fututure.  It is also good to keep raw data in its original format to troubleshoot potential issues.  \n",
    "fuctions:\n",
    "\n",
    "#### clean_data(data)\n",
    "accepts dataframe object.\n",
    "\n",
    "\n",
    "#### DQ_H6Measure(result_set,'Monthly','NSA',2022)\n",
    "\n",
    "Parameters: \n",
    "result_set: datframe object. \n",
    "\n",
    "\n",
    "frequency: string - frequency of data requested: 'Monthly', 'Yearly', etc. \n",
    "\n",
    "\n",
    "season_adj_short: string- provide seasonal adjustment paramter i.e. \"NSA\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (DataPull.py, line 66)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/pwitt/Desktop/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3418\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b30b98af4d43>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import DataPull as dp\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/pwitt/Desktop/Federal-Reserve-Econiomic-Data-Pipeline/DataPull.py\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    appended_data_2.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import DataPull as dp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_data=dp.DataPull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data=pull_data.data_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data.to_csv('result_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set=pd.read_csv('result_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set_final=pd.read_csv('result_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import DataWrangle as DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DataWrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW.DataWrangle.clean_data('self',result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set[result_set.series_id=='DEMDEPNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW.DataWrangle.DQ_H6Measure(result_set,'Monthly','NSA',2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQ_H6Measure(data,frequency,season_adj_short,year):\n",
    "        print(data.columns)\n",
    "\n",
    "\n",
    "        \"\"\"This fucntion creates a datasets for Data Quality Measure. Test \"\"\"\n",
    "\n",
    "        money_market=['DEMDEPNS','MDLNM','CURRNS']\n",
    "        import numpy as np\n",
    "\n",
    "        filtered_data=data[(data.name==\"H.6 Money Stock Measures\")&\\\n",
    "                           (data.frequency==frequency)&\\\n",
    "                           (data.seasonal_adjustment_short==season_adj_short)&(data.year==year)]\n",
    "\n",
    "        final_analysis=filtered_data[filtered_data.series_id.isin(money_market)].groupby(['title','series_id','date'])\\\n",
    "        .agg({\"value\":np.sum}).reset_index()\n",
    "\n",
    "        final_analysis['value']=final_analysis['value'].astype(float)\n",
    "        \n",
    "        print(data.columns)\n",
    "\n",
    "\n",
    "        M1=filtered_data[filtered_data.series_id=='M1NS'].groupby(['title','series_id','date']).agg({'date': lambda x:x.iloc[0],\\\n",
    "                                                                                                     \"value\":np.sum}).reset_index()\n",
    "        M1.rename(columns={'value':'groupTotal'},inplace=True)\n",
    "\n",
    "\n",
    "        M1.groupTotal=M1.groupTotal.astype(float)\n",
    "        \n",
    "        print(M1.head())\n",
    "\n",
    "        pivot1=final_analysis.pivot(index='date',columns='title',values='value')\n",
    "\n",
    "        final_pivot=pivot1.reset_index()\n",
    "        final_pivot['sum_from_component']=final_pivot.iloc[:, 1:].sum(axis=1)\n",
    "        \n",
    "        #print(final_pivot.columns)\n",
    "        print()\n",
    "\n",
    "        final_subtraction=final_pivot.merge(M1[['date','groupTotal']],how='inner',on=\"date\")\n",
    "        final_subtraction['solution']=final_subtraction.iloc[:, -2]-final_subtraction.iloc[:, -1]\n",
    "\n",
    "\n",
    "        return final_subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQ_H6Measure(result_set,'Monthly','NSA',2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_fred_pull['date']=pd.to_datetime(new_fred_pull['date'])\n",
    "#new_fred_pull['year']=new_fred_pull['date'].dt.year\n",
    "#new_fred_pull['month']=new_fred_pull['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the os module\n",
    "import os\n",
    "\n",
    "#to get the current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQ_H6Measure(data,frequency,season_adj_short,year):\n",
    "    \"\"\"This fucntion creates a datasets for Data Quality Measure. \"\"\"\n",
    "\n",
    "    money_market=['DEMDEPNS','MDLNM','CURRNS']\n",
    "    import numpy as np\n",
    "\n",
    "    filtered_data=data[(data.name==\"H.6 Money Stock Measures\")&\\\n",
    "                       (data.frequency==frequency)&\\\n",
    "                       (data.seasonal_adjustment_short==season_adj_short)&(data.year==year)]\n",
    "\n",
    "    final_analysis=filtered_data[filtered_data.series_id.isin(money_market)].groupby(['title','series_id','date'])\\\n",
    "    .agg({\"value\":np.sum}).reset_index()\n",
    "\n",
    "    final_analysis['value']=final_analysis['value'].astype(float)\n",
    "\n",
    "\n",
    "    M1=filtered_data[filtered_data.series_id=='M1NS'].groupby(['title','series_id','date']).agg({\"value\":np.sum}).reset_index()\n",
    "    M1.rename(columns={'value':'groupTotal'},inplace=True)\n",
    "\n",
    "\n",
    "    M1.groupTotal=M1.groupTotal.astype(float)\n",
    "\n",
    "    pivot1=final_analysis.pivot(index='date',columns='title',values='value')\n",
    "\n",
    "    final_pivot=pivot1.reset_index()\n",
    "    final_pivot['sum_from_component']=final_pivot.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "    final_subtraction=final_pivot.merge(M1[['date','groupTotal']],how='inner')\n",
    "    final_subtraction['solution']=final_subtraction.iloc[:, -2]-final_subtraction.iloc[:, -1]\n",
    "\n",
    "\n",
    "    return final_subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality=DQ_H6Measure(new_fred_pull,'Monthly',\"NSA\",2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
